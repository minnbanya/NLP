{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Skipgram, SkipgramNeg, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing training data\n",
    "Data = pickle.load(open('./app/models/Data.pkl', 'rb'))\n",
    "corpus = Data['corpus']\n",
    "vocab = Data['vocab']\n",
    "word2index = Data['word2index']\n",
    "voc_size = Data['voc_size']\n",
    "embed_size = Data['embedding_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_v): Embedding(9775, 50)\n",
       "  (embedding_u): Embedding(9775, 50)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model and load saved parameters\n",
    "skipgram = Skipgram(voc_size, embed_size)\n",
    "skipgram.load_state_dict(torch.load('app/models/Skipgram-v1.pt'))\n",
    "skipgram.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipgramNeg(\n",
       "  (embedding_center): Embedding(9775, 50)\n",
       "  (embedding_outside): Embedding(9775, 50)\n",
       "  (logsigmoid): LogSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model and load saved parameters\n",
    "skipgramNeg = SkipgramNeg(voc_size, embed_size)\n",
    "skipgramNeg.load_state_dict(torch.load('app/models/SkipgramNeg-v1.pt'))\n",
    "skipgramNeg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glove(\n",
       "  (center_embedding): Embedding(9775, 50)\n",
       "  (outside_embedding): Embedding(9775, 50)\n",
       "  (center_bias): Embedding(9775, 1)\n",
       "  (outside_bias): Embedding(9775, 1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model and load saved parameters\n",
    "glove = Glove(voc_size, embed_size)\n",
    "glove.load_state_dict(torch.load('app/models/GloVe-v1.pt'))\n",
    "glove.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.100d.txt')  #search on the google\n",
    "gensim = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True, limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for semantic and syntatic analysis\n",
    "def similarities(lines, model):\n",
    "    # Prepare the vectors of all the words\n",
    "    all_word_vectors = []\n",
    "    for word in vocab:\n",
    "        all_word_vectors.append(model.get_vector(word))\n",
    "    all_word_vectors = torch.stack(all_word_vectors)\n",
    "\n",
    "    correct = 0\n",
    "    # Perform vector manipulation for each set of four words\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "\n",
    "        # Assuming there are four words in each line\n",
    "        vectors = []\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                word = word.lower()\n",
    "                vectors.append(skipgram.get_vector(word))\n",
    "            else:\n",
    "                vectors.append(skipgram.get_vector('<UNK>'))\n",
    "        \n",
    "        # Perform vector manipulation (e.g., subtraction, addition)\n",
    "        result_vector = vectors[1][0] - vectors[0][0] + vectors[2][0]\n",
    "        \n",
    "        # Add a batch dimension to result_vector\n",
    "        result_vector = result_vector.unsqueeze(0)\n",
    "\n",
    "        # Calculate cosine similarities\n",
    "        similarities = F.cosine_similarity(result_vector, all_word_vectors)\n",
    "\n",
    "        # Find the index of the word with the highest similarity\n",
    "        closest_word_index = torch.argmax(similarities).item()\n",
    "\n",
    "        # Get the closest word from vocabulary\n",
    "        closest_word = vocab[closest_word_index]\n",
    "        if closest_word == words[3]:\n",
    "            correct+=1\n",
    "\n",
    "        # print(f\"The word with the closest cosine similarity to the result of {line} is: {closest_word}\")\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    print(f'Accuracy : {(correct / len(lines)) * 100: .2f}%')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Semantic and Syntatic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and create a list of tuples\n",
    "with open('./Test data/semantic(capital country).txt', 'r') as file:\n",
    "    sem_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and create a list of tuples\n",
    "with open('./Test data/syntatic(past tense).txt', 'r') as file:\n",
    "    syn_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  0.00%\n"
     ]
    }
   ],
   "source": [
    "similarities(sem_lines, skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  0.00%\n"
     ]
    }
   ],
   "source": [
    "similarities(syn_lines, skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram Negative Sampling model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  0.00%\n"
     ]
    }
   ],
   "source": [
    "similarities(sem_lines, skipgramNeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  0.00%\n"
     ]
    }
   ],
   "source": [
    "similarities(syn_lines, skipgramNeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  0.00%\n"
     ]
    }
   ],
   "source": [
    "similarities(sem_lines, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  0.00%\n"
     ]
    }
   ],
   "source": [
    "similarities(syn_lines, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe(Gensim) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(lines):\n",
    "    correct = 0\n",
    "    # Perform vector manipulation for each set of four words\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i].lower() # Convert all words to lower case\n",
    "            if words[i] not in gensim: # Check if gensim contains the word\n",
    "                words[i] = 'unknown' # Set as unknown if not\n",
    "                \n",
    "        result = gensim.most_similar(positive=[words[2], words[1]], negative=[words[0]])\n",
    "\n",
    "        # Get the closest word from most similar output\n",
    "        closest_word = result[0][0]\n",
    "        if closest_word == words[3]:\n",
    "            correct += 1\n",
    "\n",
    "        # print(f\"The word with the closest cosine similarity to the result of {line} is: {closest_word}\")\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    print(f'Accuracy : {(correct / len(lines)) * 100: .2f}%')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  93.87%\n"
     ]
    }
   ],
   "source": [
    "analogy(sem_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Accuracy :  55.45%\n"
     ]
    }
   ],
   "source": [
    "analogy(syn_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and create a list of tuples\n",
    "with open('./Test data/wordsim_similarity_goldstandard.txt', 'r') as file:\n",
    "    sim_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A.flatten(), B.flatten())\n",
    "    norm_a = np.linalg.norm(A)\n",
    "    norm_b = np.linalg.norm(B)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(lines, model):\n",
    "    scores_real = [] # Store scores in test file\n",
    "    scores_pred = [] # Store cosine similarities of models\n",
    "\n",
    "    # Loop through test file\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        vec = [] # Empty array to store word vectors\n",
    "        for word in words[:2]: # Assuming first two words are to be compared\n",
    "            try:\n",
    "                vec.append(model.get_vector(word).detach().numpy())\n",
    "            except:\n",
    "                vec.append(model.get_vector('<UNK>').detach().numpy())\n",
    "        scores_real.append(float(words[2])) # Third word should be score\n",
    "        scores_pred.append(cosine_similarity(np.array(vec[0]), np.array(vec[1])))\n",
    "\n",
    "    return spearmanr(scores_real, scores_pred) # Spearman rank-value correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram correlation score: 0.008293643289343964\n"
     ]
    }
   ],
   "source": [
    "print(f'Skipgram correlation score: {similar(sim_lines,skipgram)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram (Negative sampling) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram (Neg) correlation score: 0.08838395787478513\n"
     ]
    }
   ],
   "source": [
    "print(f'Skipgram (Neg) correlation score: {similar(sim_lines,skipgramNeg)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram correlation score: -0.0013843071649341963\n"
     ]
    }
   ],
   "source": [
    "print(f'Skipgram correlation score: {similar(sim_lines,glove)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe (Gensim) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar function but for gensim (because gensim vectors does not need to be detached)\n",
    "def similar_gensim(lines, model):\n",
    "    scores_real = []\n",
    "    scores_pred = []\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        vec = []\n",
    "        for word in words[:2]:\n",
    "            try:\n",
    "                vec.append(model.get_vector(word))\n",
    "            except:\n",
    "                vec.append(model.get_vector('unknown'))\n",
    "        scores_real.append(float(words[2]))\n",
    "        scores_pred.append(cosine_similarity(np.array(vec[0]), np.array(vec[1])))\n",
    "\n",
    "    return spearmanr(scores_real, scores_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram correlation score: 0.5962863369934295\n"
     ]
    }
   ],
   "source": [
    "print(f'Skipgram correlation score: {similar_gensim(sim_lines,gensim)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar function but for human input\n",
    "def similar_human(lines):\n",
    "    scores_real = []\n",
    "    scores_pred = []\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        scores_real.append(float(words[2]))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Ask the user for input\n",
    "                human_score = float(input(f\"How would you rate the relation between '{words[0]}' and '{words[1]}' on a scale of 0 to 10: \"))\n",
    "                \n",
    "                # Check if the input is within the valid range (0 to 10)\n",
    "                if 0 <= human_score <= 10:\n",
    "                    scores_pred.append(human_score)\n",
    "                    break  # Exit the loop if the input is valid\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter a score between 0 and 10.\")\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numeric value.\")\n",
    "\n",
    "    return spearmanr(scores_real, scores_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Please enter a numeric value.\n",
      "Invalid input. Please enter a score between 0 and 10.\n",
      "Human correlation score: 0.6637109000604999\n"
     ]
    }
   ],
   "source": [
    "print(f'Human correlation score: {similar_human(sim_lines)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test scores tabulated in README file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
